{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64333217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,Dataset,concatenate_datasets \n",
    "from glob import glob\n",
    "import os,torch,random\n",
    "from shutil import copyfile\n",
    "cache_dir = '' \n",
    "model_name = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\"\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f612a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dataset = load_dataset(\"wnut_17\",cache_dir=cache_dir)\n",
    "label_list = ['O','B-phenotype','I-phenotype','B-coding_system','I-coding_system','B-code','I-code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9009d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(files):\n",
    "    data_dict = {'id':[],'tokens':[],'ner_tags':[]}\n",
    "    i=0\n",
    "    for file in files:\n",
    "        with open(file,'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "            tokens = []\n",
    "            tags = []\n",
    "            for line in lines:\n",
    "                if line != '':\n",
    "                    token,tag = line.split('\\t')\n",
    "                    tokens.append(token)\n",
    "                    if tag!='O':\n",
    "                        tag = tag.split('-')[0]+'-'+tag.split('-')[1].lower()\n",
    "                    tags.append(label_list.index(tag))\n",
    "                else:\n",
    "                    data_dict['id'].append(str(i))\n",
    "                    data_dict['tokens'].append(tokens)\n",
    "                    data_dict['ner_tags'].append(tags)\n",
    "                    tokens = []\n",
    "                    tags = []\n",
    "                    i+=1\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {}\n",
    "for i,label in enumerate(label_list):\n",
    "    id2label.update({i:label})\n",
    "label2id = {}\n",
    "for i,label in enumerate(label_list):\n",
    "    label2id.update({label:i})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92520bb-feab-45de-9654-e94ce27ed452",
   "metadata": {},
   "source": [
    "### human annotation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90682cf1-257f-47a0-a36e-081dba22ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob(f'./data/NER/human_annotated/train.bio')\n",
    "valid_files = glob(f'./data/NER/human_annotated/dev.bio')\n",
    "test_files = glob(f'./data/NER/human_annotated/test.bio')\n",
    "train = Dataset.from_dict(data_loader(train_files))\n",
    "valid = Dataset.from_dict(data_loader(valid_files))\n",
    "test = Dataset.from_dict(data_loader(test_files))\n",
    "\n",
    "template_dataset['train'] = train\n",
    "template_dataset['validation'] = valid\n",
    "template_dataset['test'] = test\n",
    "        \n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "tokenized_dataset = template_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list), id2label=id2label, label2id=label2id,cache_dir=cache_dir\n",
    ")\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./models/NER_BiomedBERT/\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    do_predict = True,\n",
    "    metric_for_best_model = 'f1'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "\n",
    "predictions, labels, metrics = trainer.predict(tokenized_dataset['test'], metric_key_prefix=\"predict\")\n",
    "\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e02da-4635-4f1a-9205-338dad8ad63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_metrics import classification_report\n",
    "from pprint import pprint\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for sentence, predictions,golds in zip(template_dataset['test']['tokens'], true_predictions, template_dataset['test']['ner_tags']):\n",
    "    for token,tag,gold in zip(sentence,predictions,golds):\n",
    "        y_true.append(label_list[gold])\n",
    "        y_pred.append(tag)\n",
    "lenient = classification_report(tags_true=y_true, tags_pred=y_pred, mode=\"lenient\") # for lenient match\n",
    "strict = classification_report(tags_true=y_true, tags_pred=y_pred, mode=\"strict\")\n",
    "print ('entity','\\t','precision','\\t','recall','\\t','f1-score')\n",
    "for entity in strict.keys():\n",
    "    scores = strict[entity]\n",
    "    print (entity,'\\t',scores['precision'],'\\t',scores['recall'],'\\t',scores['f1-score'])\n",
    "for entity in lenient.keys():\n",
    "    scores = lenient[entity]\n",
    "    print (entity,'\\t',scores['precision'],'\\t',scores['recall'],'\\t',scores['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca47742",
   "metadata": {},
   "source": [
    "### synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob(f'./data/NER/synthetic/train.bio')\n",
    "valid_files = glob(f'./data/NER/synthetic/dev.bio')\n",
    "test_files = glob(f'./data/NER/human_annotated/test.bio')\n",
    "train = Dataset.from_dict(data_loader(train_files))\n",
    "valid = Dataset.from_dict(data_loader(valid_files))\n",
    "test = Dataset.from_dict(data_loader(test_files))\n",
    "\n",
    "template_dataset['train'] = train\n",
    "template_dataset['validation'] = valid\n",
    "template_dataset['test'] = test\n",
    "        \n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "tokenized_dataset = template_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "tokenized_dataset = template_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list), id2label=id2label, label2id=label2id,cache_dir=cache_dir\n",
    ")\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./models/NER_BiomedBERT_synthetic/\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    do_predict = True,\n",
    "    metric_for_best_model = 'f1'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "\n",
    "predictions, labels, metrics = trainer.predict(tokenized_dataset['test'], metric_key_prefix=\"predict\")\n",
    "\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "with open(f'./results/NER_BiomedBERT_synthetic_all.txt','w') as output_file:\n",
    "    for sentence, predictions,golds in zip(template_dataset['test']['tokens'], true_predictions, template_dataset['test']['ner_tags']):\n",
    "        for token,tag,gold in zip(sentence,predictions,golds):\n",
    "            output_file.write(f'{token}\\t{label_list[gold]}\\t{tag}\\n')\n",
    "        output_file.write('\\n')         \n",
    "        \n",
    "!python /data/yhu5/CLAMP/melaxdev-deepmeddocker_tf-28b7a60e460b/dockersimple/evaluate_jianfu_new.py -lf ./results/NER_BiomedBERT_synthetic_all.txt\n",
    "\n",
    "from ner_metrics import classification_report\n",
    "from pprint import pprint\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for sentence, predictions,golds in zip(template_dataset['test']['tokens'], true_predictions, template_dataset['test']['ner_tags']):\n",
    "    for token,tag,gold in zip(sentence,predictions,golds):\n",
    "        y_true.append(label_list[gold])\n",
    "        y_pred.append(tag)\n",
    "lenient = classification_report(tags_true=y_true, tags_pred=y_pred, mode=\"lenient\") # for lenient match\n",
    "strict = classification_report(tags_true=y_true, tags_pred=y_pred, mode=\"strict\")\n",
    "print ('entity','\\t','precision','\\t','recall','\\t','f1-score')\n",
    "for entity in strict.keys():\n",
    "    scores = strict[entity]\n",
    "    print (entity,'\\t',scores['precision'],'\\t',scores['recall'],'\\t',scores['f1-score'])\n",
    "for entity in lenient.keys():\n",
    "    scores = lenient[entity]\n",
    "    print (entity,'\\t',scores['precision'],'\\t',scores['recall'],'\\t',scores['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3748aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = glob(f'./data/NER/human_annotated/train.bio')\n",
    "valid_files = glob(f'./data/NER/human_annotated/dev.bio')\n",
    "test_files = glob(f'./data/NER/human_annotated/test.bio')\n",
    "train = Dataset.from_dict(data_loader(train_files))\n",
    "valid = Dataset.from_dict(data_loader(valid_files))\n",
    "test = Dataset.from_dict(data_loader(test_files))\n",
    "\n",
    "template_dataset['train'] = train\n",
    "template_dataset['validation'] = valid\n",
    "template_dataset['test'] = test\n",
    "        \n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,cache_dir=cache_dir)\n",
    "tokenized_dataset = template_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    f\"./models/NER_BiomedBERT_synthetic/\", num_labels=len(label_list), id2label=id2label, label2id=label2id,cache_dir=cache_dir\n",
    ")\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./models/NER_BiomedBERT_synthetic_continual/\",\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    do_predict = True,\n",
    "    metric_for_best_model = 'f1'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "\n",
    "predictions, labels, metrics = trainer.predict(tokenized_dataset['test'], metric_key_prefix=\"predict\")\n",
    "\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "\n",
    "from ner_metrics import classification_report\n",
    "from pprint import pprint\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for sentence, predictions,golds in zip(template_dataset['test']['tokens'], true_predictions, template_dataset['test']['ner_tags']):\n",
    "    for token,tag,gold in zip(sentence,predictions,golds):\n",
    "        y_true.append(label_list[gold])\n",
    "        y_pred.append(tag)\n",
    "lenient = classification_report(tags_true=y_true, tags_pred=y_pred, mode=\"lenient\") # for lenient match\n",
    "strict = classification_report(tags_true=y_true, tags_pred=y_pred, mode=\"strict\")\n",
    "print ('entity','\\t','precision','\\t','recall','\\t','f1-score')\n",
    "for entity in strict.keys():\n",
    "    scores = strict[entity]\n",
    "    print (entity,'\\t',scores['precision'],'\\t',scores['recall'],'\\t',scores['f1-score'])\n",
    "for entity in lenient.keys():\n",
    "    scores = lenient[entity]\n",
    "    print (entity,'\\t',scores['precision'],'\\t',scores['recall'],'\\t',scores['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf00e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "llama2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
